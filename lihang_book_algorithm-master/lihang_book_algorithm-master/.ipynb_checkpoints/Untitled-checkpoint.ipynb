{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start read data\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-46e4b14779cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0mtime_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[0mraw_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'E:/19人工智能实践and20机器学习/机器学习/lihang_book_algorithm-master/lihang_book_algorithm-master/data/train.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\rgpython2\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\rgpython2\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\rgpython2\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\rgpython2\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2035\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2036\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2037\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2038\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2039\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: out of memory"
     ]
    }
   ],
   "source": [
    "#encoding=utf-8\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import random\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 二值化\n",
    "def binaryzation(img):\n",
    "    cv_img = img.astype(np.uint8)\n",
    "    cv2.threshold(cv_img,50,1,cv2.cv.CV_THRESH_BINARY_INV,cv_img)\n",
    "    return cv_img\n",
    "\n",
    "def Train(trainset,train_labels):\n",
    "    prior_probability = np.zeros(class_num)                         # 先验概率\n",
    "    conditional_probability = np.zeros((class_num,feature_len,2))   # 条件概率\n",
    "\n",
    "    # 计算先验概率及条件概率\n",
    "    for i in range(len(train_labels)):\n",
    "        img = binaryzation(trainset[i])     # 图片二值化\n",
    "        label = train_labels[i]\n",
    "\n",
    "        prior_probability[label] += 1\n",
    "\n",
    "        for j in range(feature_len):\n",
    "            conditional_probability[label][j][img[j]] += 1\n",
    "\n",
    "    # 将概率归到[1.10001]\n",
    "    for i in range(class_num):\n",
    "        for j in range(feature_len):\n",
    "\n",
    "            # 经过二值化后图像只有0，1两种取值\n",
    "            pix_0 = conditional_probability[i][j][0]\n",
    "            pix_1 = conditional_probability[i][j][1]\n",
    "\n",
    "            # 计算0，1像素点对应的条件概率\n",
    "            probalility_0 = (float(pix_0)/float(pix_0+pix_1))*1000000 + 1\n",
    "            probalility_1 = (float(pix_1)/float(pix_0+pix_1))*1000000 + 1\n",
    "\n",
    "            conditional_probability[i][j][0] = probalility_0\n",
    "            conditional_probability[i][j][1] = probalility_1\n",
    "\n",
    "    return prior_probability,conditional_probability\n",
    "\n",
    "# 计算概率\n",
    "def calculate_probability(img,label):\n",
    "    probability = int(prior_probability[label])\n",
    "\n",
    "    for i in range(len(img)):\n",
    "        probability *= int(conditional_probability[label][i][img[i]])\n",
    "\n",
    "    return probability\n",
    "\n",
    "def Predict(testset,prior_probability,conditional_probability):\n",
    "    predict = []\n",
    "\n",
    "    for img in testset:\n",
    "\n",
    "        # 图像二值化\n",
    "        img = binaryzation(img)\n",
    "\n",
    "        max_label = 0\n",
    "        max_probability = calculate_probability(img,0)\n",
    "\n",
    "        for j in range(1,10):\n",
    "            probability = calculate_probability(img,j)\n",
    "\n",
    "            if max_probability < probability:\n",
    "                max_label = j\n",
    "                max_probability = probability\n",
    "\n",
    "        predict.append(max_label)\n",
    "\n",
    "    return np.array(predict)\n",
    "\n",
    "\n",
    "class_num = 10\n",
    "feature_len = 784\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    print( 'Start read data')\n",
    "\n",
    "    time_1 = time.time()\n",
    "\n",
    "    raw_data = pd.read_csv('E:/19人工智能实践and20机器学习/机器学习/lihang_book_algorithm-master/lihang_book_algorithm-master/data/train.csv',header=0)\n",
    "    data = raw_data.values\n",
    "\n",
    "    imgs = data[0::,1::]\n",
    "    labels = data[::,0]\n",
    "\n",
    "    # 选取 2/3 数据作为训练集， 1/3 数据作为测试集\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(imgs, labels, test_size=0.33, random_state=23323)\n",
    "    # print train_features.shape\n",
    "    # print train_features.shape\n",
    "\n",
    "    time_2 = time.time()\n",
    "    print ('read data cost ',time_2 - time_1,' second','\\n')\n",
    "\n",
    "    print ('Start training')\n",
    "    prior_probability,conditional_probability = Train(train_features,train_labels)\n",
    "    time_3 = time.time()\n",
    "    print ('training cost ',time_3 - time_2,' second','\\n')\n",
    "\n",
    "    print ('Start predicting')\n",
    "    test_predict = Predict(test_features,prior_probability,conditional_probability)\n",
    "    time_4 = time.time()\n",
    "    print ('predicting cost ',time_4 - time_3,' second','\\n')\n",
    "\n",
    "    score = accuracy_score(test_labels,test_predict)\n",
    "    print (\"The accruacy socre is \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print('Start read data')? (<ipython-input-10-ff3efdbf5c90>, line 123)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-ff3efdbf5c90>\"\u001b[1;36m, line \u001b[1;32m123\u001b[0m\n\u001b[1;33m    print 'Start read data'\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print('Start read data')?\n"
     ]
    }
   ],
   "source": [
    "# encoding=utf-8\n",
    "\n",
    "# @Author: WenDesi\n",
    "\n",
    "# @Date:   09-08-16\n",
    "\n",
    "# @Email:  wendesi@foxmail.com\n",
    "\n",
    "# @Last modified by:   WenDesi\n",
    "\n",
    "# @Last modified time: 08-11-16\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "\n",
    "import random\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Perceptron(object):\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.learning_step = 0.00001\n",
    "\n",
    "        self.max_iteration = 5000\n",
    "\n",
    "\n",
    "\n",
    "    def predict_(self, x):\n",
    "\n",
    "        wx = sum([self.w[j] * x[j] for j in xrange(len(self.w))])\n",
    "\n",
    "        return int(wx > 0)\n",
    "\n",
    "\n",
    "\n",
    "    def train(self, features, labels):\n",
    "\n",
    "        self.w = [0.0] * (len(features[0]) + 1)\n",
    "\n",
    "\n",
    "\n",
    "        correct_count = 0\n",
    "\n",
    "        time = 0\n",
    "\n",
    "\n",
    "\n",
    "        while time < self.max_iteration:\n",
    "\n",
    "            index = random.randint(0, len(labels) - 1)\n",
    "\n",
    "            x = list(features[index])\n",
    "\n",
    "            x.append(1.0)\n",
    "\n",
    "            y = 2 * labels[index] - 1\n",
    "\n",
    "            wx = sum([self.w[j] * x[j] for j in xrange(len(self.w))])\n",
    "\n",
    "\n",
    "\n",
    "            if wx * y > 0:\n",
    "\n",
    "                correct_count += 1\n",
    "\n",
    "                if correct_count > self.max_iteration:\n",
    "\n",
    "                    break\n",
    "\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "            for i in xrange(len(self.w)):\n",
    "\n",
    "                self.w[i] += self.learning_step * (y * x[i])\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self,features):\n",
    "\n",
    "        labels = []\n",
    "\n",
    "        for feature in features:\n",
    "\n",
    "            x = list(feature)\n",
    "\n",
    "            x.append(1)\n",
    "\n",
    "            labels.append(self.predict_(x))\n",
    "\n",
    "        return labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "\n",
    "\n",
    "    print 'Start read data'\n",
    "\n",
    "\n",
    "\n",
    "    time_1 = time.time()\n",
    "\n",
    "\n",
    "\n",
    "    raw_data = pd.read_csv('../data/train_binary.csv', header=0)\n",
    "\n",
    "    data = raw_data.values\n",
    "\n",
    "\n",
    "\n",
    "    imgs = data[0::, 1::]\n",
    "\n",
    "    labels = data[::, 0]\n",
    "\n",
    "\n",
    "\n",
    "    # 选取 2/3 数据作为训练集， 1/3 数据作为测试集\n",
    "\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "\n",
    "        imgs, labels, test_size=0.33, random_state=23323)\n",
    "\n",
    "    # print train_features.shape\n",
    "\n",
    "    # print train_features.shape\n",
    "\n",
    "\n",
    "\n",
    "    time_2 = time.time()\n",
    "\n",
    "    print 'read data cost ', time_2 - time_1, ' second', '\\n'\n",
    "\n",
    "\n",
    "\n",
    "    print 'Start training'\n",
    "\n",
    "    p = Perceptron()\n",
    "\n",
    "    p.train(train_features, train_labels)\n",
    "\n",
    "\n",
    "\n",
    "    time_3 = time.time()\n",
    "\n",
    "    print 'training cost ', time_3 - time_2, ' second', '\\n'\n",
    "\n",
    "\n",
    "\n",
    "    print 'Start predicting'\n",
    "\n",
    "    test_predict = p.predict(test_features)\n",
    "\n",
    "    time_4 = time.time()\n",
    "\n",
    "    print 'predicting cost ', time_4 - time_3, ' second', '\\n'\n",
    "\n",
    "\n",
    "\n",
    "    score = accuracy_score(test_labels, test_predict)\n",
    "\n",
    "    print \"The accruacy socre is \", score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start read data\n",
      "read data cost  3.286228895187378  second \n",
      "\n",
      "Start training\n",
      "training cost  30.01067280769348  second \n",
      "\n",
      "Start predicting\n",
      "predicting cost  290.1427323818207  second \n",
      "\n",
      "The accruacy socre is  0.8336940836940837\n"
     ]
    }
   ],
   "source": [
    "#encoding=utf-8\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 二值化\n",
    "def binaryzation(img):\n",
    "    cv_img = img.astype(np.uint8)\n",
    "    cv2.threshold(cv_img,50,1,cv2.THRESH_BINARY_INV,cv_img)\n",
    "    return cv_img\n",
    "\n",
    "def Train(trainset,train_labels):\n",
    "    prior_probability = np.zeros(class_num)                         # 先验概率\n",
    "    conditional_probability = np.zeros((class_num,feature_len,2))   # 条件概率\n",
    "\n",
    "    # 计算先验概率及条件概率\n",
    "    for i in range(len(train_labels)):\n",
    "        img = binaryzation(trainset[i])     # 图片二值化\n",
    "        label = train_labels[i]\n",
    "\n",
    "        prior_probability[label] += 1\n",
    "\n",
    "        for j in range(feature_len):\n",
    "            conditional_probability[label][j][img[j]] += 1\n",
    "\n",
    "    # 将概率归到[1.10001]\n",
    "    for i in range(class_num):\n",
    "        for j in range(feature_len):\n",
    "\n",
    "            # 经过二值化后图像只有0，1两种取值\n",
    "            pix_0 = conditional_probability[i][j][0]\n",
    "            pix_1 = conditional_probability[i][j][1]\n",
    "\n",
    "            # 计算0，1像素点对应的条件概率\n",
    "            probalility_0 = (float(pix_0)/float(pix_0+pix_1))*1000000 + 1\n",
    "            probalility_1 = (float(pix_1)/float(pix_0+pix_1))*1000000 + 1\n",
    "\n",
    "            conditional_probability[i][j][0] = probalility_0\n",
    "            conditional_probability[i][j][1] = probalility_1\n",
    "\n",
    "    return prior_probability,conditional_probability\n",
    "\n",
    "# 计算概率\n",
    "def calculate_probability(img,label):\n",
    "    probability = int(prior_probability[label])\n",
    "\n",
    "    for i in range(len(img)):\n",
    "        probability *= int(conditional_probability[label][i][img[i]])\n",
    "\n",
    "    return probability\n",
    "\n",
    "def Predict(testset,prior_probability,conditional_probability):\n",
    "    predict = []\n",
    "\n",
    "    for img in testset:\n",
    "\n",
    "        # 图像二值化\n",
    "        img = binaryzation(img)\n",
    "\n",
    "        max_label = 0\n",
    "        max_probability = calculate_probability(img,0)\n",
    "\n",
    "        for j in range(1,10):\n",
    "            probability = calculate_probability(img,j)\n",
    "\n",
    "            if max_probability < probability:\n",
    "                max_label = j\n",
    "                max_probability = probability\n",
    "\n",
    "        predict.append(max_label)\n",
    "\n",
    "    return np.array(predict)\n",
    "\n",
    "\n",
    "class_num = 10\n",
    "feature_len = 784\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    print ('Start read data')\n",
    "\n",
    "    time_1 = time.time()\n",
    "\n",
    "    raw_data = pd.read_csv('E:/19人工智能实践and20机器学习/机器学习/lihang_book_algorithm-master/lihang_book_algorithm-master/data/train.csv',header=0)\n",
    "    data = raw_data.values\n",
    "\n",
    "    imgs = data[0::,1::]\n",
    "    labels = data[::,0]\n",
    "\n",
    "    # 选取 2/3 数据作为训练集， 1/3 数据作为测试集\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(imgs, labels, test_size=0.33, random_state=23323)\n",
    "    # print train_features.shape\n",
    "    # print train_features.shape\n",
    "\n",
    "    time_2 = time.time()\n",
    "    print ('read data cost ',time_2 - time_1,' second','\\n')\n",
    "\n",
    "    print ('Start training')\n",
    "    prior_probability,conditional_probability = Train(train_features,train_labels)\n",
    "    time_3 = time.time()\n",
    "    print ('training cost ',time_3 - time_2,' second','\\n')\n",
    "\n",
    "    print ('Start predicting')\n",
    "    test_predict = Predict(test_features,prior_probability,conditional_probability)\n",
    "    time_4 = time.time()\n",
    "    print ('predicting cost ',time_4 - time_3,' second','\\n')\n",
    "\n",
    "    score = accuracy_score(test_labels,test_predict)\n",
    "    print (\"The accruacy socre is \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start read data\n",
      "read data cost  3.702260732650757  second \n",
      "\n",
      "Start training\n",
      "training cost  30.23219323158264  second \n",
      "\n",
      "Start predicting\n",
      "predicting cost  255.71131205558777  second \n",
      "\n",
      "The accruacy socre is  0.8334054834054834\n"
     ]
    }
   ],
   "source": [
    "#encoding=utf-8\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 二值化\n",
    "def binaryzation(img):\n",
    "    cv_img = img.astype(np.uint8)\n",
    "    cv2.threshold(cv_img,50,1,cv2.THRESH_BINARY_INV,cv_img)\n",
    "    return cv_img\n",
    "\n",
    "def Train(trainset,train_labels):\n",
    "    prior_probability = np.zeros(class_num)                         # 先验概率\n",
    "    conditional_probability = np.zeros((class_num,feature_len,2))   # 条件概率\n",
    "\n",
    "    # 计算先验概率及条件概率\n",
    "    for i in range(len(train_labels)):\n",
    "        img = binaryzation(trainset[i])     # 图片二值化\n",
    "        label = train_labels[i]\n",
    "\n",
    "        prior_probability[label] += 1\n",
    "\n",
    "        for j in range(feature_len):\n",
    "            conditional_probability[label][j][img[j]] += 1\n",
    "\n",
    "    # 将概率归到[1.10001]\n",
    "    for i in range(class_num):\n",
    "        for j in range(feature_len):\n",
    "\n",
    "            # 经过二值化后图像只有0，1两种取值\n",
    "            pix_0 = conditional_probability[i][j][0]\n",
    "            pix_1 = conditional_probability[i][j][1]\n",
    "\n",
    "            # 计算0，1像素点对应的条件概率\n",
    "            probalility_0 = (float(pix_0)/float(pix_0+pix_1))*100000 + 1\n",
    "            probalility_1 = (float(pix_1)/float(pix_0+pix_1))*100000 + 1\n",
    "\n",
    "            conditional_probability[i][j][0] = probalility_0\n",
    "            conditional_probability[i][j][1] = probalility_1\n",
    "\n",
    "    return prior_probability,conditional_probability\n",
    "\n",
    "# 计算概率\n",
    "def calculate_probability(img,label):\n",
    "    probability = int(prior_probability[label])\n",
    "\n",
    "    for i in range(len(img)):\n",
    "        probability *= int(conditional_probability[label][i][img[i]])\n",
    "\n",
    "    return probability\n",
    "\n",
    "def Predict(testset,prior_probability,conditional_probability):\n",
    "    predict = []\n",
    "\n",
    "    for img in testset:\n",
    "\n",
    "        # 图像二值化\n",
    "        img = binaryzation(img)\n",
    "\n",
    "        max_label = 0\n",
    "        max_probability = calculate_probability(img,0)\n",
    "\n",
    "        for j in range(1,10):\n",
    "            probability = calculate_probability(img,j)\n",
    "\n",
    "            if max_probability < probability:\n",
    "                max_label = j\n",
    "                max_probability = probability\n",
    "\n",
    "        predict.append(max_label)\n",
    "\n",
    "    return np.array(predict)\n",
    "\n",
    "\n",
    "class_num = 10\n",
    "feature_len = 784\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    print ('Start read data')\n",
    "\n",
    "    time_1 = time.time()\n",
    "\n",
    "    raw_data = pd.read_csv('E:/19人工智能实践and20机器学习/机器学习/lihang_book_algorithm-master/lihang_book_algorithm-master/data/train.csv',header=0)\n",
    "    data = raw_data.values\n",
    "\n",
    "    imgs = data[0::,1::]\n",
    "    labels = data[::,0]\n",
    "\n",
    "    # 选取 2/3 数据作为训练集， 1/3 数据作为测试集\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(imgs, labels, test_size=0.33, random_state=23323)\n",
    "    # print train_features.shape\n",
    "    # print train_features.shape\n",
    "\n",
    "    time_2 = time.time()\n",
    "    print ('read data cost ',time_2 - time_1,' second','\\n')\n",
    "\n",
    "    print ('Start training')\n",
    "    prior_probability,conditional_probability = Train(train_features,train_labels)\n",
    "    time_3 = time.time()\n",
    "    print ('training cost ',time_3 - time_2,' second','\\n')\n",
    "\n",
    "    print ('Start predicting')\n",
    "    test_predict = Predict(test_features,prior_probability,conditional_probability)\n",
    "    time_4 = time.time()\n",
    "    print ('predicting cost ',time_4 - time_3,' second','\\n')\n",
    "\n",
    "    score = accuracy_score(test_labels,test_predict)\n",
    "    print (\"The accruacy socre is \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
