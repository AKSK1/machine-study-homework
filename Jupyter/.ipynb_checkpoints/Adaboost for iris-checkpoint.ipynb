{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.pyplot:Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n",
      "DEBUG:root:iterater 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start read data\n",
      "读取数据花费了  0.005982875823974609  second \n",
      "\n",
      "开始训练\n",
      "\n",
      "正在处理第 0 个特征\n",
      "***第 0 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.10666666666666667\n",
      "***第 0 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.09870646766169168\n",
      "***第 0 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.09783469492897658\n",
      "***第 0 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.09774015613561667\n",
      "***第 0 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.09772991492130703\n",
      "***第 0 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.09772880563815568\n",
      "***第 0 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.0977286854870101\n",
      "***第 0 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.09772867247294943\n",
      "***第 0 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.09772867106334361\n",
      "***第 0 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.09772867091066333\n",
      "***第 0 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.09772867089412585\n",
      "***第 0 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.09772867089233465\n",
      "***第 0 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.0977286708921406\n",
      "***第 0 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.0977286708921195\n",
      "***第 0 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.09772867089211729\n",
      "***第 0 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.09772867089211715\n",
      "***第 0 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.09772867089211706\n",
      "***第 0 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.09772867089211697\n",
      "***第 0 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.09772867089211684\n",
      "***第 0 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.011595893323583129\n",
      "***第 0 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.0001376193711599111\n",
      "第 0 类特征的总分类器寻找完毕\n",
      "\n",
      "\n",
      "正在处理第 1 个特征\n",
      "***第 1 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.17333333333333334\n",
      "***第 1 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.11950372208436727\n",
      "***第 1 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.11229434223968787\n",
      "***第 1 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.06802382539151636\n",
      "***第 1 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.06408302746770655\n",
      "***第 1 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.06381319769753697\n",
      "***第 1 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.06379480532068849\n",
      "***第 1 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.06379355202909472\n",
      "***第 1 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.06379346662921026\n",
      "***第 1 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.06379346081003001\n",
      "***第 1 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.06379346041350897\n",
      "***第 1 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.06379346038648989\n",
      "***第 1 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.06379346038464888\n",
      "***第 1 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.06379346038452355\n",
      "***第 1 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.06379346038451504\n",
      "***第 1 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.06379346038451453\n",
      "***第 1 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.06379346038451443\n",
      "***第 1 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.06379346038451433\n",
      "***第 1 个特征创建了分类器***\n",
      "该分类器的误差率为： 0.0046216512433932665\n",
      "\n",
      "正在处理第 2 个特征\n",
      "***第 2 个特征创建了分类器***\n",
      "该分类器的误差率为： 0\n",
      "第 2 类特征的总分类器寻找完毕\n",
      "\n",
      "\n",
      "正在处理第 3 个特征\n",
      "***第 3 个特征创建了分类器***\n",
      "该分类器的误差率为： 0\n",
      "第 3 类特征的总分类器寻找完毕\n",
      "\n",
      "一共产生了 83 个分类器\n",
      "\n",
      "训练花费了  0.7569756507873535  second \n",
      "\n",
      "开始测试\n",
      "测试花费了  0.0019943714141845703  second \n",
      "\n",
      "测试准确度为：  0.92\n",
      "\n",
      "点集如下\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x192cae88d08>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "import logging\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from IPython.core import debugger\n",
    "debug = debugger.Pdb().set_trace\n",
    "\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "class Sign(object):\n",
    "    '''\n",
    "    阈值分类器\n",
    "    有两种方向，\n",
    "        1）x<v y=1\n",
    "        2) x>v y=1\n",
    "        v 是阈值轴\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,features,labels,w):\n",
    "        self.X = features               # 训练数据特征\n",
    "        \n",
    "        self.Y = labels                 # 训练数据的标签\n",
    "        self.N = len(labels)            # 训练数据大小\n",
    "        self.Xmax=max(features)\n",
    "        self.w = w                      # 训练数据权值分布\n",
    "        self.allw=sum(w)                # 一般来说都为1 \n",
    "        self.v = np.linspace(0,10,41)   # v的可选范围\n",
    "        \n",
    "    def _train_less_than_(self):\n",
    "        '''\n",
    "        寻找(x<v y=1)情况下的最优v\n",
    "        '''\n",
    "\n",
    "        index = -1\n",
    "        error_score = 100000000\n",
    "\n",
    "        for v in self.v:\n",
    "            score = 0\n",
    "            for j in range(self.N):\n",
    "                val = -1\n",
    "                if self.X[j]<v:\n",
    "                    val = 1\n",
    "\n",
    "                if val*self.Y[j]<0:\n",
    "                    score += self.w[j]\n",
    "            \n",
    "            \n",
    "            if score < error_score:   #取值为v，筛选处最优的Gm\n",
    "                index = v\n",
    "                error_score = score\n",
    "\n",
    "        return index,error_score\n",
    "\n",
    "\n",
    "\n",
    "    def _train_more_than_(self):\n",
    "        '''\n",
    "        寻找(x>v y=1)情况下的最优v\n",
    "        '''\n",
    "\n",
    "        index = -1\n",
    "        error_score = 100000000\n",
    "\n",
    "        for i in self.v:\n",
    "            score = 0\n",
    "            for j in range(self.N):\n",
    "                val = 1\n",
    "                if self.X[j]<i:\n",
    "                    val = -1\n",
    "\n",
    "                if val*self.Y[j]<0:\n",
    "                    score += self.w[j]\n",
    "                \n",
    "            if score < error_score:    #取值为v，筛选处最优的Gm\n",
    "                index = i\n",
    "                error_score = score\n",
    "\n",
    "        return index,error_score\n",
    "\n",
    "    def train(self):                   #确定是哪种分类器（大于v为1还是小于v为1）\n",
    "        \n",
    "        time1 = time.time()\n",
    "        less_v,less_score = self._train_less_than_()\n",
    "        more_v,more_score = self._train_more_than_()\n",
    "        time2 = time.time()\n",
    "        \n",
    "\n",
    "        if less_score < more_score:\n",
    "            self.is_less = True\n",
    "            self.v = less_v\n",
    "            return less_score\n",
    "\n",
    "        else:\n",
    "            self.is_less = False\n",
    "            self.v = more_v\n",
    "            return more_score\n",
    "\n",
    "    def predict(self,feature):  # Gm(x)  \n",
    "                                \n",
    "                                #判断输入的特征在分类器中是一类还是二类（大于v还是小于v为1）\n",
    "        if self.is_less>0:      #如果是小于v为1的分类器\n",
    "            if feature<self.v:\n",
    "                return 1.0       \n",
    "            else:\n",
    "                return -1.0\n",
    "        else:                  #如果是大于v为1的分类器\n",
    "            if feature<self.v:\n",
    "                return -1.0\n",
    "            else:\n",
    "                return 1.0\n",
    "            \n",
    "class AdaBoost(object):\n",
    "    \n",
    "    def _init_(self):\n",
    "        pass\n",
    "        \n",
    "    def _init_parameters_(self,features,labels):   #features是特征，labels是标签，要在输入前分开\n",
    "        self.X = features                          ###特征features的格式是[index,i]的矩阵，该程序中所有index都是行，i都是列###\n",
    "        self.Y = labels\n",
    "        self.n = len(features[0])                  #每个数据的特征个数\n",
    "        \n",
    "        self.N = len(labels)                       #数据个数\n",
    "        self.M = 1                                 #训练几次这个程序（无用），为1 即可\n",
    "        self.w = [1.0/self.N]*self.N               #初始化w为1/N，这就是Di\n",
    "        self.alpha = []                            #就是公式里的alpha\n",
    "        self.classifier = []                       #用来存分类器\n",
    "        self.Z=0\n",
    "    \n",
    "    def _w_(self,index,classifier,i):              #计算 wm*e(-alpha*y*g)\n",
    "                                                   #index是数据的位置，i是数据中特征的序号  \n",
    "                                    \n",
    "        return self.w[index]*np.exp(-self.alpha[-1][1]*self.Y[index]*classifier.predict(self.X[index][i]))\n",
    "    \n",
    "    def _Z_(self,i,classifier):    #求Zm\n",
    "        Z=0\n",
    "        for index in range(self.N):\n",
    "            Z += self._w_(index,classifier,i)\n",
    "        return Z                   #返回Zm\n",
    "    \n",
    "    def train(self,features,labels):\n",
    "\n",
    "        self._init_parameters_(features,labels)\n",
    "\n",
    "        for times in range(self.M):\n",
    "            logging.debug('iterater %d' % times)\n",
    "            \n",
    "            time1 = time.time()\n",
    "            map_time = 0\n",
    "\n",
    "                   \n",
    "            for i in range(self.n):\n",
    "                print()\n",
    "                print('正在处理第',i,'个特征')\n",
    "                best_classifier = (0.5,None,None)  #当前正在定义的分类器(误差率,针对的特征，分类器)\n",
    "                map_time -= time.time()\n",
    "                features = self.X[:,i]\n",
    "                map_time += time.time()\n",
    "                em=0.5\n",
    "                self.w = [1.0/self.N]*self.N\n",
    "                con=0\n",
    "                while(em>=0.01):                   #100个数据如果没有全部判断对，就不断寻找该特征的分类器\n",
    "                    \n",
    "                    classifier = Sign(features,self.Y,self.w)    #分类器\n",
    "                    error_score = classifier.train()             #分类器的错误率\n",
    "\n",
    "                    if error_score < best_classifier[0]:         #第一个分类器如果分类器错误率小于0.5，就可以说是一个分类器\n",
    "                                                                 #只采纳错误率更低的分类器，但是准确率会降低\n",
    "                    \n",
    "                    #if error_score < 0.5:                       #所有产生的分类器都采用，不管错误率是比原来高还是低，最终的准确率会提高    \n",
    "                                                        #这两个if都可以使用，前者分类器少，后者分类器多且准确率高\n",
    "                        best_classifier = (error_score,i,classifier)\n",
    "                        print('***第',i,'个特征创建了分类器***')\n",
    "                        print('该分类器的误差率为：',best_classifier[0])\n",
    "                    #else:\n",
    "                        #print('！！第',i,'类没有合适的分类器！！')\n",
    "                        \n",
    "                    em = best_classifier[0]\n",
    "                    #print('该分类器的误差率为：',em)\n",
    "\n",
    "                    if em==0:\n",
    "                        alpha=(i,1)                 #self.alpha[a][b],a代表第几个alpha，b为0则显示是哪个特征的alpha，b为1则显示alpha的值\n",
    "                        self.alpha.append(alpha)\n",
    "                    else:\n",
    "                        alpha=(i,0.5*math.log((1-em)/em))\n",
    "                        self.alpha.append(alpha)\n",
    "\n",
    "                    self.classifier.append(best_classifier[1:])   \n",
    "                    #if con>0: \n",
    "                        #if self.alpha[-1][1]==self.alpha[-2][1]:\n",
    "                            #self.classifier=np.delete(self.classifier,-1,axis=0)\n",
    "                           # break\n",
    "                \n",
    "                    con+=1\n",
    "                    if con>self.N:                #防止陷入死循环，限制分类器的个数\n",
    "                        print('实在找不到了更好的分类器了')\n",
    "                        print()\n",
    "                        break\n",
    "                    Z = self._Z_(best_classifier[1],best_classifier[2])   #best_classifier[1]表示的是哪一种特征,best_classifier[2]表示的是分类器\n",
    "                    \n",
    "                    # 更新训练集权值分布 8.4\n",
    "                    for ii in range(self.N):\n",
    "                        self.w[ii] = self._w_(ii,best_classifier[2],best_classifier[1])/Z\n",
    "                                 \n",
    "                if (em<0.001):                     #错误率达到标准就可以停止寻找分类器了\n",
    "                    print('第',i,'类特征的总分类器寻找完毕')\n",
    "                    print()\n",
    "\n",
    "            \n",
    "        #print(self.classifier)       #解除#则可以观看产生的分类器\n",
    "        alphaspahe=np.shape(self.alpha)\n",
    "        self.alphanum=alphaspahe[0]\n",
    "        \n",
    "        print('一共产生了',self.alphanum,'个分类器')\n",
    "        print()\n",
    "        #classifiernum=np.shape(self.classifier)[0]\n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "        \n",
    "    def _predict_(self,featuresnum,testnum,testth,feature):\n",
    "        result = 0.0\n",
    "        donateone=0            #分类器投给标签 1 的票数\n",
    "        donatezero=0           #分类器投给标签-1 的票数\n",
    "        for i in range(featuresnum):           #第i个特征\n",
    "            \n",
    "            for anum in range(self.alphanum):  #每一个分类器都拿出来用\n",
    "               \n",
    "                if i==(self.alpha[anum][0]):   #保证使用的分类器是属于这一个特征的\n",
    "                    result+=self.alpha[anum][1]*self.classifier[anum][1].predict(feature[i])     \n",
    "            \n",
    "            if result>0:        #分类器投票\n",
    "                donateone +=1 \n",
    "            else:\n",
    "                donatezero +=1\n",
    "        if donateone>donatezero:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "            \n",
    "        \n",
    "    def predict(self,features):\n",
    "        featuresnum=None\n",
    "        featuresnum=np.shape(features)[1]    #测试集的特征个数\n",
    "        testnum=np.shape(features)[0]        #测试集的数据个数\n",
    "        results = []\n",
    "        \n",
    "        for testth in range(testnum):        #开始测试第testth个数据为哪一类\n",
    "            results.append(self._predict_(featuresnum,testnum,testth,features[testth]))\n",
    "        return results\n",
    "\n",
    "# 鸢尾花(iris)数据集\n",
    "# 数据集内包含 3 类共 150 条记录，每类各 50 个数据，\n",
    "# 每条记录都有 4 项特征：花萼长度、花萼宽度、花瓣长度、花瓣宽度，\n",
    "# 可以通过这4个特征预测鸢尾花卉属于（iris-setosa, iris-versicolour, iris-virginica）中的哪一品种。\n",
    "# 这里只取前100条记录，四项特征，两个类别。\n",
    "\n",
    "def create_data():\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['label'] = iris.target\n",
    "    df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']\n",
    "    data = np.array(df.iloc[:100, [0, 1,2,3, -1]])\n",
    "    for i in range(len(data)):\n",
    "        if data[i,-1] == 0:\n",
    "            data[i,-1] = -1\n",
    "    # print(data)\n",
    "    return data[:,:-1], data[:,-1]  \n",
    "\n",
    "\n",
    "#开始运行\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "print('Start read data')\n",
    "time_1=time.time()\n",
    "\n",
    "X, y = create_data()    #分开数据和标签，X为数据，y为标签\n",
    "y[y > 0] = 1\n",
    "y[y == 0] = -1\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(X, y, test_size=0.25, random_state=55)\n",
    "            \n",
    "time_2=time.time()\n",
    "print('读取数据花费了 ',time_2 - time_1,' second','\\n')\n",
    "print('开始训练')\n",
    "\n",
    "\n",
    "ada = AdaBoost()\n",
    "ada.train(train_features,train_labels)\n",
    "#print(ada.alpha)\n",
    "time_3= time.time()\n",
    "print('训练花费了 ',time_3 - time_2,' second','\\n')\n",
    "\n",
    "print('开始测试')\n",
    "test_predict = ada.predict(test_features)\n",
    "time_4=time.time()\n",
    "\n",
    "print('测试花费了 ',time_4 - time_3,' second','\\n')\n",
    "\n",
    "score = accuracy_score(test_labels,test_predict)\n",
    "\n",
    "print(\"测试准确度为： \", score)\n",
    "    #def sign(value):\n",
    "        #if value >:\n",
    "          #  return 1\n",
    "      #  else:\n",
    "         #   return -1\n",
    "print()\n",
    "print('点集如下')\n",
    "plt.scatter(train_features[train_labels==1,0],train_features[train_labels==1,1], marker='o', c='r', label='1')\n",
    "plt.scatter(train_features[train_labels==-1,0],train_features[train_labels==-1,1], marker='o', c='b', label='-1')\n",
    "plt.scatter(test_features[test_labels==1,0],test_features[test_labels==1,1], marker='x', c='r')\n",
    "plt.scatter(test_features[test_labels==-1,0], test_features[test_labels==-1,1], marker='x', c='b')    \n",
    "        \n",
    "   \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.pyplot:Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n",
      "DEBUG:root:iterater 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start read data\n",
      "read data cost  0.005983829498291016  second \n",
      "\n",
      "Start training\n",
      "正在处理第 0 个特征\n",
      "***第 0 个特征创建了分类器***\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "！！第 0 类没有合适的分类器！！\n",
      "该分类其的em为： 0.12222222222222223\n",
      "实在找不到了\n",
      "正在处理第 1 个特征\n",
      "***第 1 个特征创建了分类器***\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "！！第 1 类没有合适的分类器！！\n",
      "该分类其的em为： 0.17777777777777773\n",
      "实在找不到了\n",
      "正在处理第 2 个特征\n",
      "***第 2 个特征创建了分类器***\n",
      "该分类其的em为： 0\n",
      "第 2 类特征的总分类器寻找完毕\n",
      "正在处理第 3 个特征\n",
      "***第 3 个特征创建了分类器***\n",
      "该分类其的em为： 0\n",
      "第 3 类特征的总分类器寻找完毕\n",
      "[(0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (0, <__main__.Sign object at 0x00000268E9978E08>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (1, <__main__.Sign object at 0x00000268E9AB8F48>), (2, <__main__.Sign object at 0x00000268E9AB8988>), (3, <__main__.Sign object at 0x00000268E9AB8C48>)]\n",
      "[0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.9857762898343254, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 0.7657381854821944, 1, 1]\n",
      "training cost  1.8473424911499023  second \n",
      "\n",
      "Start predicting\n",
      "predicting cost  0.00020813941955566406  second \n",
      "\n",
      "The accruacy socre is  1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x268e9abe808>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "import logging\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from IPython.core import debugger\n",
    "debug = debugger.Pdb().set_trace\n",
    "\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "# 鸢尾花(iris)数据集\n",
    "# 数据集内包含 3 类共 150 条记录，每类各 50 个数据，\n",
    "# 每条记录都有 4 项特征：花萼长度、花萼宽度、花瓣长度、花瓣宽度，\n",
    "# 可以通过这4个特征预测鸢尾花卉属于（iris-setosa, iris-versicolour, iris-virginica）中的哪一品种。\n",
    "# 这里只取前100条记录，两项特征，两个类别。\n",
    "\n",
    "class Sign(object):\n",
    "    '''\n",
    "    阈值分类器\n",
    "    有两种方向，\n",
    "        1）x<v y=1\n",
    "        2) x>v y=1\n",
    "        v 是阈值轴\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,features,labels,w):\n",
    "        self.X = features               # 训练数据特征\n",
    "        \n",
    "        self.Y = labels                 # 训练数据的标签\n",
    "        self.N = len(labels)        # 训练数据大小\n",
    "        self.Xmax=max(features)\n",
    "        self.w = w                      # 训练数据权值分布\n",
    "        self.v = np.linspace(0,10,41)       # 阈值轴可选范围\n",
    "        \n",
    "    def _train_less_than_(self):\n",
    "        '''\n",
    "        寻找(x<v y=1)情况下的最优v\n",
    "        '''\n",
    "\n",
    "        index = -1\n",
    "        error_score = 100000000\n",
    "\n",
    "        for v in self.v:\n",
    "            score = 0\n",
    "            for j in range(self.N):\n",
    "                val = -1\n",
    "                if self.X[j]<v:\n",
    "                    val = 1\n",
    "\n",
    "                if val*self.Y[j]<0:\n",
    "                    score += self.w[j]\n",
    "\n",
    "            if score < error_score:\n",
    "                index = v\n",
    "                error_score = score\n",
    "\n",
    "        return index,error_score\n",
    "\n",
    "\n",
    "\n",
    "    def _train_more_than_(self):\n",
    "        '''\n",
    "        寻找(x>v y=1)情况下的最优v\n",
    "        '''\n",
    "\n",
    "        index = -1\n",
    "        error_score = 100000000\n",
    "\n",
    "        for i in self.v:\n",
    "            score = 0\n",
    "            for j in range(self.N):\n",
    "                val = 1\n",
    "                if self.X[j]<i:\n",
    "                    val = -1\n",
    "\n",
    "                if val*self.Y[j]<0:\n",
    "                    score += self.w[j]\n",
    "\n",
    "            if score < error_score:    #筛选处最优的Gm\n",
    "                index = i\n",
    "                error_score = score\n",
    "\n",
    "        return index,error_score\n",
    "\n",
    "    def train(self):                 #确定是哪种分类器（大于v为1还是小于v为1）\n",
    "        \n",
    "        time1 = time.time()\n",
    "        less_v,less_score = self._train_less_than_()\n",
    "        more_v,more_score = self._train_more_than_()\n",
    "        time2 = time.time()\n",
    "        \n",
    "\n",
    "        if less_score < more_score:\n",
    "            self.is_less = True\n",
    "            self.v = less_v\n",
    "            return less_score\n",
    "\n",
    "        else:\n",
    "            self.is_less = False\n",
    "            self.v = more_v\n",
    "            return more_score\n",
    "\n",
    "    def predict(self,feature):  #Gm(x)  \n",
    "                                #判断输入的特征在分类器中是一类还是二类\n",
    "        if self.is_less>0:    #如果是小于v为1的分类器\n",
    "            if feature<self.v:\n",
    "                return 1.0       \n",
    "            else:\n",
    "                return -1.0\n",
    "        else:                  #如果是大于v为1的分类器\n",
    "            if feature<self.v:\n",
    "                return -1.0\n",
    "            else:\n",
    "                return 1.0\n",
    "            \n",
    "class AdaBoost(object):\n",
    "    \n",
    "    def _init_(self):\n",
    "        pass\n",
    "        \n",
    "    def _init_parameters_(self,features,labels):   #features是特征，labels是标签，要在输入前分开\n",
    "        self.X = features\n",
    "        self.Y = labels\n",
    "        self.n = len(features[0])   #特征个数\n",
    "        \n",
    "        self.N = len(labels)        #一种特征的数据个数\n",
    "        self.M = 1\n",
    "        self.w = [1.0/self.N]*self.N   #初始化w为1/N，这就是Di\n",
    "        self.alpha = []         \n",
    "        self.classifier = []\n",
    "        self.Z=0\n",
    "    \n",
    "    def _w_(self,index,classifier,i):    #计算wm+1\n",
    "                                         #index是数据的位置，i是特征的序号  \n",
    "                                         #暂时不带Zm\n",
    "       \n",
    "        return self.w[index]*np.exp(-self.alpha[-1]*self.Y[index]*classifier.predict(self.X[index][i]))\n",
    "    \n",
    "    def _Z_(self,i,classifier):    #求Zm\n",
    "        \n",
    "        Z=0\n",
    "\n",
    "        for index in range(self.N):\n",
    "            Z += self._w_(index,classifier,i)\n",
    "            #Z += self.w(index)*np.exp(-self.alpha[-1]*self.Y[index]*classifier.predict(self.X[index][i]))\n",
    "        return Z\n",
    "    \n",
    "    def train(self,features,labels):\n",
    "\n",
    "        self._init_parameters_(features,labels)\n",
    "\n",
    "        for times in range(self.M):\n",
    "            logging.debug('iterater %d' % times)\n",
    "            \n",
    "            time1 = time.time()\n",
    "            map_time = 0\n",
    "\n",
    "                   \n",
    "            for i in range(self.n):\n",
    "                print('正在处理第',i,'个特征')\n",
    "                best_classifier = (0.5,None,None)  #(误差率,针对的特征，分类器)\n",
    "                map_time -= time.time()\n",
    "                features = self.X[:,i]\n",
    "                map_time += time.time()\n",
    "                em=0.5\n",
    "                self.w = [1.0/self.N]*self.N\n",
    "                con=0\n",
    "                while(em>=0.01):           #如果没有全部判断对，就不断寻找该特征的多个分类器\n",
    "                    \n",
    "                    classifier = Sign(features,self.Y,self.w)    #分类器\n",
    "                    error_score = classifier.train()             #分类器的错误率\n",
    "\n",
    "                    if error_score < best_classifier[0]:         #第一个分类器如果分类器错误率小于0.5，就可以说是一个分类器\n",
    "                                                                 #后面产生的分类器如果不比前一个分类器好，就不是一个分类器\n",
    "                        best_classifier = (error_score,i,classifier)\n",
    "                        print('***第',i,'个特征创建了分类器***')\n",
    "                    else:\n",
    "                        print('！！第',i,'类没有合适的分类器！！')\n",
    "                        \n",
    "                    em = best_classifier[0]\n",
    "                    print('该分类其的em为：',em)\n",
    "\n",
    "                    if em==0:\n",
    "                                    #self.alpha[a][b],a代表第几个alpha，b为0则显示是哪个特征的alpha，b为1则显示alpha的值\n",
    "                        self.alpha.append(1)\n",
    "                    else:\n",
    "                        alpha=0.5*math.log((1-em)/em)\n",
    "                        self.alpha.append(alpha)\n",
    "\n",
    "                    self.classifier.append(best_classifier[1:])\n",
    "                \n",
    "                    con+=1\n",
    "                    if con>self.N:       #防止陷入死循环\n",
    "                        print('实在找不到了')\n",
    "                        break\n",
    "                    Z = self._Z_(best_classifier[1],best_classifier[2])   #best_classifier[1]表示的是哪一项特征,\n",
    "                if (em<0.01):   \n",
    "                    print('第',i,'类特征的总分类器寻找完毕')                                                      #best_classifier[2]表示的是Gm（x）分类器\n",
    "\n",
    "            # 更新训练集权值分布 8.4\n",
    "                    for ii in range(self.N):\n",
    "                        self.w[ii] = self._w_(ii,best_classifier[2],best_classifier[1])/Z\n",
    "        print(self.classifier)\n",
    "        \n",
    "    def _predict_(self,feature):\n",
    "        result = 0.0\n",
    "        for i in range(self.n):\n",
    "            #for index1 in range(self.n):\n",
    "                \n",
    "            index=self.classifier[i][0]     #是哪一个特征的分类器\n",
    "            classifier = self.classifier[i][1]   #拿出该分类器\n",
    "            #print(feature)\n",
    "            #print(feature[index])\n",
    "            result+=self.alpha[i]*classifier.predict(feature[index])    #分类器f(x)=sign(alpha*Gm(x))\n",
    "        \n",
    "        if result>0:    #分类器投票\n",
    "            return 1 \n",
    "        else:\n",
    "            return -1\n",
    "    def predict(self,features):\n",
    "        results = []\n",
    "        for feature in features:\n",
    "            results.append(self._predict_(feature))\n",
    "        return results\n",
    "\n",
    "def create_data():\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['label'] = iris.target\n",
    "    df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']\n",
    "    data = np.array(df.iloc[:100, [0, 1,2,3, -1]])\n",
    "    for i in range(len(data)):\n",
    "        if data[i,-1] == 0:\n",
    "            data[i,-1] = -1\n",
    "    # print(data)\n",
    "    return data[:,:-1], data[:,-1]  \n",
    "\n",
    "\n",
    "#开始运行\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "print('Start read data')\n",
    "time_1=time.time()\n",
    "\n",
    "X, y = create_data()\n",
    "y[y > 0] = 1\n",
    "y[y == 0] = -1\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(X, y, test_size=0.1, random_state=65)\n",
    "            \n",
    "time_2=time.time()\n",
    "print('read data cost ',time_2 - time_1,' second','\\n')\n",
    "print('Start training')\n",
    "\n",
    "ada = AdaBoost()\n",
    "ada.train(train_features,train_labels)\n",
    "print(ada.alpha)\n",
    "time_3= time.time()\n",
    "print('training cost ',time_3 - time_2,' second','\\n')\n",
    "\n",
    "print('Start predicting')\n",
    "test_predict = ada.predict(test_features)\n",
    "time_4=time.time()\n",
    "\n",
    "print('predicting cost ',time_4 - time_3,' second','\\n')\n",
    "\n",
    "score = accuracy_score(test_labels,test_predict)\n",
    "\n",
    "print(\"The accruacy socre is \", score)\n",
    "    #def sign(value):\n",
    "        #if value >:\n",
    "          #  return 1\n",
    "      #  else:\n",
    "         #   return -1\n",
    "plt.scatter(train_features[train_labels==1,0],train_features[train_labels==1,1], marker='o', c='r', label='1')\n",
    "plt.scatter(train_features[train_labels==-1,0],train_features[train_labels==-1,1], marker='o', c='b', label='-1')\n",
    "plt.scatter(test_features[test_labels==1,0],test_features[test_labels==1,1], marker='x', c='r')\n",
    "plt.scatter(test_features[test_labels==-1,0], test_features[test_labels==-1,1], marker='x', c='b')    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]]\n",
      "[[3.5 1.4 0.2]\n",
      " [3.  1.4 0.2]\n",
      " [3.2 1.3 0.2]\n",
      " [3.1 1.5 0.2]\n",
      " [3.6 1.4 0.2]\n",
      " [3.9 1.7 0.4]\n",
      " [3.4 1.4 0.3]\n",
      " [3.4 1.5 0.2]\n",
      " [2.9 1.4 0.2]\n",
      " [3.1 1.5 0.1]\n",
      " [3.7 1.5 0.2]\n",
      " [3.4 1.6 0.2]\n",
      " [3.  1.4 0.1]\n",
      " [3.  1.1 0.1]\n",
      " [4.  1.2 0.2]\n",
      " [4.4 1.5 0.4]\n",
      " [3.9 1.3 0.4]\n",
      " [3.5 1.4 0.3]\n",
      " [3.8 1.7 0.3]\n",
      " [3.8 1.5 0.3]\n",
      " [3.4 1.7 0.2]\n",
      " [3.7 1.5 0.4]\n",
      " [3.6 1.  0.2]\n",
      " [3.3 1.7 0.5]\n",
      " [3.4 1.9 0.2]\n",
      " [3.  1.6 0.2]\n",
      " [3.4 1.6 0.4]\n",
      " [3.5 1.5 0.2]\n",
      " [3.4 1.4 0.2]\n",
      " [3.2 1.6 0.2]\n",
      " [3.1 1.6 0.2]\n",
      " [3.4 1.5 0.4]\n",
      " [4.1 1.5 0.1]\n",
      " [4.2 1.4 0.2]\n",
      " [3.1 1.5 0.2]\n",
      " [3.2 1.2 0.2]\n",
      " [3.5 1.3 0.2]\n",
      " [3.6 1.4 0.1]\n",
      " [3.  1.3 0.2]\n",
      " [3.4 1.5 0.2]\n",
      " [3.5 1.3 0.3]\n",
      " [2.3 1.3 0.3]\n",
      " [3.2 1.3 0.2]\n",
      " [3.5 1.6 0.6]\n",
      " [3.8 1.9 0.4]\n",
      " [3.  1.4 0.3]\n",
      " [3.8 1.6 0.2]\n",
      " [3.2 1.4 0.2]\n",
      " [3.7 1.5 0.2]\n",
      " [3.3 1.4 0.2]\n",
      " [3.2 4.7 1.4]\n",
      " [3.2 4.5 1.5]\n",
      " [3.1 4.9 1.5]\n",
      " [2.3 4.  1.3]\n",
      " [2.8 4.6 1.5]\n",
      " [2.8 4.5 1.3]\n",
      " [3.3 4.7 1.6]\n",
      " [2.4 3.3 1. ]\n",
      " [2.9 4.6 1.3]\n",
      " [2.7 3.9 1.4]\n",
      " [2.  3.5 1. ]\n",
      " [3.  4.2 1.5]\n",
      " [2.2 4.  1. ]\n",
      " [2.9 4.7 1.4]\n",
      " [2.9 3.6 1.3]\n",
      " [3.1 4.4 1.4]\n",
      " [3.  4.5 1.5]\n",
      " [2.7 4.1 1. ]\n",
      " [2.2 4.5 1.5]\n",
      " [2.5 3.9 1.1]\n",
      " [3.2 4.8 1.8]\n",
      " [2.8 4.  1.3]\n",
      " [2.5 4.9 1.5]\n",
      " [2.8 4.7 1.2]\n",
      " [2.9 4.3 1.3]\n",
      " [3.  4.4 1.4]\n",
      " [2.8 4.8 1.4]\n",
      " [3.  5.  1.7]\n",
      " [2.9 4.5 1.5]\n",
      " [2.6 3.5 1. ]\n",
      " [2.4 3.8 1.1]\n",
      " [2.4 3.7 1. ]\n",
      " [2.7 3.9 1.2]\n",
      " [2.7 5.1 1.6]\n",
      " [3.  4.5 1.5]\n",
      " [3.4 4.5 1.6]\n",
      " [3.1 4.7 1.5]\n",
      " [2.3 4.4 1.3]\n",
      " [3.  4.1 1.3]\n",
      " [2.5 4.  1.3]\n",
      " [2.6 4.4 1.2]\n",
      " [3.  4.6 1.4]\n",
      " [2.6 4.  1.2]\n",
      " [2.3 3.3 1. ]\n",
      " [2.7 4.2 1.3]\n",
      " [3.  4.2 1.2]\n",
      " [2.9 4.2 1.3]\n",
      " [2.9 4.3 1.3]\n",
      " [2.5 3.  1.1]\n",
      " [2.8 4.1 1.3]]\n"
     ]
    }
   ],
   "source": [
    "YYY=X\n",
    "print(X)\n",
    "\n",
    "YY=np.delete(YYY,0,axis=1)\n",
    "print(YY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha is :0.07330173709593753\n",
      "alpha is :0.19453564916624264\n",
      "alpha is :0.6051610885090357\n",
      "alpha is :nan\n",
      "{'WClassifier0': [4, 5.1, 0.07330173709593753], 'WClassifier1': [4, 5.1, 0.19453564916624264], 'WClassifier2': [4, 5.1, 0.6051610885090357], 'WClassifier3': [4, 5.1, nan]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\newpython\\python3.7.6\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in log\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x22f13634f48>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Adaboost分类\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "def calculateAlpha(error):    #Gm(x)的系数\n",
    "    if error == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (1/2) * (np.log((1-error)/error))\n",
    "\n",
    "def calculateWeight(alpha, originalWeight, y, g):      #更新权重\n",
    "    weight = originalWeight * (np.e ** (-alpha * y * g))\n",
    "    return weight\n",
    "\n",
    "def sign(value):   #  Gm(x)\n",
    "    if value > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def learn(x, alpha, featureValue):\n",
    "    if x >= featureValue:\n",
    "        return sign(alpha * 1)\n",
    "    else:\n",
    "        return sign(alpha * -1)\n",
    "\n",
    "\n",
    "def findBestCut(dataset, target, weights):\n",
    "    shape = np.shape(dataset)\n",
    "    featureNo = shape[1]\n",
    "    newWeights = []\n",
    "    for featureSeq in range(featureNo):   # 4种特征都有各自的分类器\n",
    "        featureRow = dataset[:, featureSeq]    #提取1种特征\n",
    "        for featureIndex in range(len(featureRow)):   \n",
    "            featureValue = featureRow[featureIndex]   #提取特征中的一个值\n",
    "            resultRow = featureRow.copy()\n",
    "            for index in range(len(resultRow)):        #resultRow是分类器的分类结果\n",
    "                if resultRow[index] >= featureValue:\n",
    "                    resultRow[index] = 1\n",
    "                else:\n",
    "                    resultRow[index] = -1\n",
    "\n",
    "            error = np.dot(np.multiply(resultRow, target), weights.T)   #判断该分类器是否为弱分类器\n",
    "           \n",
    "            if error < 0.5:            #如果是弱分类器，那么\n",
    "                alpha = calculateAlpha(error)\n",
    "                print('alpha is :' + str(alpha))   #输出权值\n",
    "                for weightNo in range(len(weights)):\n",
    "                    g = learn(featureRow[weightNo], alpha, featureValue)    #Gm(x)\n",
    "                    newWeights.append(calculateWeight(alpha, weights[weightNo], target[weightNo], g))\n",
    "\n",
    "                newWeights = newWeights / sum(newWeights)\n",
    "                \n",
    "                return featureValue, alpha, newWeights\n",
    "    return None, None, newWeights\n",
    "\n",
    "    # newWeights = newWeights/sum(newWeights)\n",
    "    #\n",
    "    # return featureValue, alpha, newWeights\n",
    "\n",
    "\n",
    "def adaBoost(dataset,target,weekClassifierNo=4):\n",
    "    shape = np.shape(dataset)\n",
    "    \n",
    "    recordNo = shape[0]\n",
    "  \n",
    "    weights = np.ones(recordNo)/recordNo\n",
    "    featureNo = shape[1]\n",
    "    weekClassifiers = {}\n",
    "    for classifierSeq in range(weekClassifierNo):\n",
    "        featureValue, alpha, newWeights = findBestCut(dataset, target, weights)\n",
    "        if len(newWeights) == 0:\n",
    "            break\n",
    "        weekClassifiers[\"WClassifier\" + str(classifierSeq)] = [featureNo, featureValue, alpha]\n",
    "        weights = newWeights\n",
    "    return weekClassifiers\n",
    "\n",
    "def _predict_(feature):\n",
    "    result=0.0\n",
    "    for i in range(4):\n",
    "        index = \n",
    "def predict(features):\n",
    "    result = []\n",
    "    for feature in features:\n",
    "        result.append(_predict_(feature))\n",
    "    return results\n",
    "#iris = load_iris()\n",
    "#iris.target[iris.target > 0] = 1\n",
    "#iris.target[iris.target == 0] = -1\n",
    "#train_features=iris.data\n",
    "#train_labels=iris.target\n",
    "#print(train_features)\n",
    "def create_data():\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['label'] = iris.target\n",
    "    df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']\n",
    "    data = np.array(df.iloc[:100, [0, 1,2,3, -1]])\n",
    "    for i in range(len(data)):\n",
    "        if data[i,-1] == 0:\n",
    "            data[i,-1] = -1\n",
    "    return data[:,:4], data[:,-1]\n",
    "\n",
    "irisdata,irislabels=create_data()\n",
    "train_features, text_features, train_labels, test_labels = train_test_split(irisdata, irislabels, test_size=0.18, random_state=55)\n",
    "\n",
    "weekClassifiers = adaBoost(train_features, train_labels, 50)\n",
    "print(weekClassifiers)    \n",
    "\n",
    "plt.scatter(train_features[train_labels==1,0],train_features[train_labels==1,1], \n",
    "marker='o', c='r', label='1')\n",
    "plt.scatter(train_features[train_labels==-1,0],train_features[train_labels==-1,1], \n",
    "marker='o', c='b', label='-1')\n",
    "plt.scatter(text_features[test_labels==1,0],text_features[test_labels==1,1], marker='x', \n",
    "c='r')\n",
    "plt.scatter(text_features[test_labels==-1,0], text_features[test_labels==-1,1], \n",
    "marker='x', c='b')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha is :0.09360577104407318\n",
      "alpha is :0.03509886861946332\n",
      "alpha is :0.09009038757777348\n",
      "alpha is :0.2430797244206212\n",
      "alpha is :0.17190165288528267\n",
      "alpha is :0.5145727335107108\n",
      "alpha is :nan\n",
      "{'WClassifier0': [4, 4.7, 0.09360577104407318], 'WClassifier1': [4, 4.9, 0.03509886861946332], 'WClassifier2': [4, 4.9, 0.09009038757777348], 'WClassifier3': [4, 4.9, 0.2430797244206212], 'WClassifier4': [4, 5.1, 0.17190165288528267], 'WClassifier5': [4, 5.1, 0.5145727335107108], 'WClassifier6': [4, 5.1, nan]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\newpython\\python3.7.6\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in log\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Adaboost分类\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "def calculateAlpha(error):\n",
    "    if error == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (1/2) * (np.log((1-error)/error))\n",
    "\n",
    "def calculateWeight(alpha, originalWeight, y, g):\n",
    "    weight = originalWeight * (np.e ** (-alpha * y * g))\n",
    "    return weight\n",
    "\n",
    "def sign(value):\n",
    "    if value > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def learn(x, alpha, featureValue):\n",
    "    if x >= featureValue:\n",
    "        return sign(alpha * 1)\n",
    "    else:\n",
    "        return sign(alpha * -1)\n",
    "\n",
    "\n",
    "def findBestCut(dataset, target, weights):\n",
    "    shape = np.shape(dataset)\n",
    "    featureNo = shape[1]\n",
    "    newWeights = []\n",
    "    for featureSeq in range(featureNo):\n",
    "        featureRow = dataset[:, featureSeq]\n",
    "        for featureIndex in range(len(featureRow)):\n",
    "            featureValue = featureRow[featureIndex]\n",
    "            resultRow = featureRow.copy()\n",
    "            for index in range(len(resultRow)):\n",
    "                if resultRow[index] >= featureValue:\n",
    "                    resultRow[index] = 1\n",
    "                else:\n",
    "                    resultRow[index] = -1\n",
    "\n",
    "            error = np.dot(np.multiply(resultRow, target), weights.T)\n",
    "           \n",
    "            if error < 0.5:\n",
    "                alpha = calculateAlpha(error)\n",
    "                print('alpha is :' + str(alpha))\n",
    "                for weightNo in range(len(weights)):\n",
    "                    g = learn(featureRow[weightNo], alpha, featureValue)\n",
    "                    newWeights.append(calculateWeight(alpha, weights[weightNo], target[weightNo], g))\n",
    "\n",
    "                newWeights = newWeights / sum(newWeights)\n",
    "                \n",
    "                return featureValue, alpha, newWeights\n",
    "    return None, None, newWeights\n",
    "\n",
    "    # newWeights = newWeights/sum(newWeights)\n",
    "    #\n",
    "    # return featureValue, alpha, newWeights\n",
    "\n",
    "\n",
    "def adaBoost(dataset,target,weekClassifierNo=4):\n",
    "    shape = np.shape(dataset)\n",
    "    recordNo = shape[0]\n",
    "    weights = np.ones(recordNo)/recordNo\n",
    "    featureNo = shape[1]\n",
    "    weekClassifiers = {}\n",
    "    for classifierSeq in range(weekClassifierNo):\n",
    "        featureValue, alpha, newWeights = findBestCut(dataset, target, weights)\n",
    "        if len(newWeights) == 0:\n",
    "            break\n",
    "        weekClassifiers[\"WClassifier\" + str(classifierSeq)] = [featureNo, featureValue, alpha]\n",
    "        weights = newWeights\n",
    "    return weekClassifiers\n",
    "\n",
    "iris = load_iris()\n",
    "iris.target[iris.target > 0] = 1\n",
    "iris.target[iris.target == 0] = -1\n",
    "weekClassifiers = adaBoost(iris.data, iris.target, 50)\n",
    "print(weekClassifiers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
